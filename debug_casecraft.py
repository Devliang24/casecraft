#!/usr/bin/env python3
"""
CaseCraft è°ƒè¯•è„šæœ¬

ç‹¬ç«‹çš„Pythonè°ƒè¯•è„šæœ¬ï¼Œç”¨äºè°ƒè¯•CaseCraftçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæ— éœ€ä½¿ç”¨CLIã€‚
å¯ä»¥åœ¨VSCodeä¸­ç›´æ¥F5è°ƒè¯•ï¼Œæ–¹ä¾¿å®šä½é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç›´æ¥è¿è¡Œ: python debug_casecraft.py
2. VSCodeè°ƒè¯•: è®¾ç½®æ–­ç‚¹åæŒ‰F5
3. å•ç‹¬æµ‹è¯•æŸä¸ªåŠŸèƒ½: ä¿®æ”¹main()å‡½æ•°ä¸­çš„è°ƒç”¨
"""

import asyncio
import json
import os
import sys
import traceback
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from casecraft.core.parsing.api_parser import APIParser
from casecraft.core.generation.llm_client import LLMClient
from casecraft.core.generation.test_generator import TestCaseGenerator
from casecraft.core.management.config_manager import ConfigManager
from casecraft.models.config import CaseCraftConfig, LLMConfig
from casecraft.utils.logging import configure_logging, get_logger


class DebugHelper:
    """è°ƒè¯•è¾…åŠ©ç±»"""
    
    def __init__(self):
        self.logger = get_logger("debug")
        # é…ç½®æ—¥å¿—ä¸ºè°ƒè¯•æ¨¡å¼
        configure_logging(log_level="DEBUG", console_output=True)
    
    def print_separator(self, title: str) -> None:
        """æ‰“å°åˆ†å‰²çº¿"""
        print(f"\n{'='*60}")
        print(f" {title}")
        print(f"{'='*60}")
    
    def print_json(self, data: Any, title: str = "JSON Data") -> None:
        """æ ¼å¼åŒ–æ‰“å°JSONæ•°æ®"""
        print(f"\n--- {title} ---")
        try:
            if isinstance(data, str):
                data = json.loads(data)
            print(json.dumps(data, indent=2, ensure_ascii=False))
        except Exception as e:
            print(f"JSONæ ¼å¼åŒ–å¤±è´¥: {e}")
            print(data)
        print()
    
    def handle_exception(self, func_name: str, e: Exception) -> None:
        """å¤„ç†å¼‚å¸¸"""
        print(f"\nâŒ {func_name} å¤±è´¥:")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print("\nå®Œæ•´å †æ ˆè·Ÿè¸ª:")
        traceback.print_exc()
        print()


async def test_config_loading(debug: DebugHelper) -> Optional[CaseCraftConfig]:
    """æµ‹è¯•é…ç½®åŠ è½½åŠŸèƒ½"""
    debug.print_separator("æµ‹è¯•é…ç½®åŠ è½½")
    
    try:
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡
        import os
        os.environ["CASECRAFT_LLM_API_KEY"] = "db474e8a869844bbbdcf1a111a5eafa4.0SY1uazDVWJQZPHA"
        os.environ["CASECRAFT_LLM_MODEL"] = "glm-4.5-x"
        os.environ["CASECRAFT_LLM_BASE_URL"] = "https://open.bigmodel.cn/api/paas/v4"
        os.environ["CASECRAFT_LLM_TIMEOUT"] = "60"
        os.environ["CASECRAFT_LLM_MAX_RETRIES"] = "3"
        os.environ["CASECRAFT_PROCESSING_WORKERS"] = "1"
        
        print("âœ… è®¾ç½®æµ‹è¯•ç¯å¢ƒå˜é‡")
        
        config_manager = ConfigManager()
        
        # ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
        config = config_manager.create_default_config()
        
        print("âœ… é…ç½®å¯¹è±¡åˆ›å»ºæˆåŠŸ:")
        print(f"Model: {config.llm.model}")
        print(f"API Key: {config.llm.api_key[:10]}...****")
        print(f"Base URL: {config.llm.base_url}")
        print(f"Timeout: {config.llm.timeout}s")
        print(f"Workers: {config.processing.workers}")
        
        return config
        
    except Exception as e:
        debug.handle_exception("test_config_loading", e)
        return None


async def test_api_parsing(debug: DebugHelper) -> Optional[Dict]:
    """æµ‹è¯•APIè§£æåŠŸèƒ½"""
    debug.print_separator("æµ‹è¯•APIè§£æ")
    
    try:
        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        test_file = Path("ecommerce_api_openapi.json")
        if not test_file.exists():
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return None
        
        print(f"âœ… æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶: {test_file}")
        
        # åˆ›å»ºAPIè§£æå™¨
        parser = APIParser()
        
        # è§£æAPIæ–‡æ¡£
        print("ğŸ”„ è§£æAPIæ–‡æ¡£...")
        api_spec = await parser.parse_from_source(str(test_file))
        
        print("âœ… APIè§£ææˆåŠŸ:")
        print(f"APIæ ‡é¢˜: {api_spec.title}")
        print(f"APIç‰ˆæœ¬: {api_spec.version}")
        print(f"APIæè¿°: {api_spec.description or 'N/A'}")
        print(f"ç«¯ç‚¹æ•°é‡: {len(api_spec.endpoints)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªç«¯ç‚¹
        print("\nå‰5ä¸ªç«¯ç‚¹:")
        for i, endpoint in enumerate(api_spec.endpoints[:5]):
            print(f"{i+1}. {endpoint.method} {endpoint.path} - {endpoint.summary}")
            
        # é€‰æ‹©ä¸€ä¸ªç«¯ç‚¹è¿›è¡Œè¯¦ç»†åˆ†æ
        if api_spec.endpoints:
            endpoint = api_spec.endpoints[0]
            print(f"\nè¯¦ç»†åˆ†æç«¯ç‚¹: {endpoint.method} {endpoint.path}")
            print(f"æè¿°: {endpoint.description}")
            print(f"æ ‡ç­¾: {endpoint.tags}")
            if endpoint.parameters:
                print(f"å‚æ•°æ•°é‡: {len(endpoint.parameters)}")
            if endpoint.request_body:
                print("è¯·æ±‚ä½“: å­˜åœ¨")
            if endpoint.responses:
                print(f"å“åº”å®šä¹‰: {list(endpoint.responses.keys())}")
        
        return {
            "api_spec": api_spec,
            "sample_endpoint": api_spec.endpoints[0] if api_spec.endpoints else None
        }
        
    except Exception as e:
        debug.handle_exception("test_api_parsing", e)
        return None


async def test_llm_client(debug: DebugHelper, config: CaseCraftConfig) -> Optional[LLMClient]:
    """æµ‹è¯•LLMå®¢æˆ·ç«¯åŠŸèƒ½"""
    debug.print_separator("æµ‹è¯•LLMå®¢æˆ·ç«¯")
    
    try:
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        llm_client = LLMClient(config.llm)
        
        print("âœ… LLMå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ:")
        print(f"Base URL: {llm_client.base_url}")
        print(f"Model: {config.llm.model}")
        print(f"Timeout: {config.llm.timeout}s")
        
        # æµ‹è¯•ç®€å•çš„LLMè°ƒç”¨
        print("\nğŸ”„ æµ‹è¯•LLMè°ƒç”¨...")
        test_prompt = "è¯·ç”¨JSONæ ¼å¼è¿”å›ä¸€ä¸ªç®€å•çš„æµ‹è¯•å“åº”ï¼ŒåŒ…å«statuså’Œmessageå­—æ®µ"
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªAPIæµ‹è¯•åŠ©æ‰‹ï¼ŒæŒ‰è¦æ±‚è¿”å›JSONæ ¼å¼çš„å“åº”"
        
        print(f"å‘é€æç¤º: {test_prompt}")
        
        response = await llm_client.generate(
            prompt=test_prompt,
            system_prompt=system_prompt
        )
        
        print("âœ… LLMå“åº”æˆåŠŸ:")
        print(f"æ¨¡å‹: {response.model}")
        print(f"å®ŒæˆåŸå› : {response.finish_reason}")
        if response.usage:
            print(f"Tokenä½¿ç”¨: {response.usage}")
        
        print("\nå“åº”å†…å®¹:")
        print(response.content)
        
        # å°è¯•è§£æå“åº”ä¸ºJSON
        try:
            parsed_response = json.loads(response.content)
            debug.print_json(parsed_response, "è§£æåçš„JSONå“åº”")
        except:
            print("âš ï¸ å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
        
        return llm_client
        
    except Exception as e:
        debug.handle_exception("test_llm_client", e)
        return None


async def test_case_generation(debug: DebugHelper, api_data: Dict, llm_client: LLMClient) -> Optional[Dict]:
    """æµ‹è¯•æµ‹è¯•ç”¨ä¾‹ç”ŸæˆåŠŸèƒ½"""
    debug.print_separator("æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ")
    
    try:
        if not api_data or not api_data.get("sample_endpoint"):
            print("âŒ éœ€è¦æœ‰æ•ˆçš„APIç«¯ç‚¹æ•°æ®")
            return None
        
        endpoint = api_data["sample_endpoint"]
        print(f"âœ… ä½¿ç”¨ç«¯ç‚¹è¿›è¡Œæµ‹è¯•: {endpoint.method} {endpoint.path}")
        
        # åˆ›å»ºæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨
        generator = TestCaseGenerator(llm_client, api_version="1.0")
        
        print("\nğŸ”„ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        print("è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿæ—¶é—´...")
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        result = await generator.generate_test_cases(endpoint)
        
        print("âœ… æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ:")
        print(f"ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(result.test_cases.test_cases)}")
        
        if result.token_usage:
            print(f"Tokenä½¿ç”¨æƒ…å†µ:")
            print(f"  æç¤ºToken: {result.token_usage.prompt_tokens}")
            print(f"  å®ŒæˆToken: {result.token_usage.completion_tokens}")
            print(f"  æ€»Token: {result.token_usage.total_tokens}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
        print(f"\nç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨:")
        for i, test_case in enumerate(result.test_cases.test_cases):
            # å®‰å…¨è·å–test_typeå€¼
            test_type = test_case.test_type.value if hasattr(test_case.test_type, 'value') else str(test_case.test_type)
            print(f"{i+1}. {test_case.name} ({test_type})")
            print(f"   æœŸæœ›çŠ¶æ€: {test_case.expected_status}")
            print(f"   æè¿°: {test_case.description[:100]}...")
            if test_case.tags:
                print(f"   æ ‡ç­¾: {', '.join(test_case.tags[:5])}")
            print()
        
        # è¯¦ç»†æ˜¾ç¤ºç¬¬ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹
        if result.test_cases.test_cases:
            first_case = result.test_cases.test_cases[0]
            debug.print_json(first_case.model_dump(), "ç¬¬ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹è¯¦æƒ…")
        
        return {
            "test_collection": result.test_cases,
            "token_usage": result.token_usage
        }
        
    except Exception as e:
        debug.handle_exception("test_case_generation", e)
        return None


async def debug_full_generation(debug: DebugHelper) -> None:
    """ç«¯åˆ°ç«¯è°ƒè¯•å®Œæ•´ç”Ÿæˆæµç¨‹"""
    debug.print_separator("ç«¯åˆ°ç«¯å®Œæ•´æµç¨‹è°ƒè¯•")
    
    try:
        # 1. åŠ è½½é…ç½®
        print("æ­¥éª¤ 1: åŠ è½½é…ç½®...")
        config = await test_config_loading(debug)
        if not config:
            print("âŒ é…ç½®åŠ è½½å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return
        
        # 2. è§£æAPI
        print("\næ­¥éª¤ 2: è§£æAPIæ–‡æ¡£...")
        api_data = await test_api_parsing(debug)
        if not api_data:
            print("âŒ APIè§£æå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return
        
        # 3. æµ‹è¯•LLMå®¢æˆ·ç«¯
        print("\næ­¥éª¤ 3: æµ‹è¯•LLMå®¢æˆ·ç«¯...")
        llm_client = await test_llm_client(debug, config)
        if not llm_client:
            print("âŒ LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return
        
        # 4. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        print("\næ­¥éª¤ 4: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        generation_result = await test_case_generation(debug, api_data, llm_client)
        if not generation_result:
            print("âŒ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return
        
        # 5. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        print("\næ­¥éª¤ 5: ä¿å­˜è°ƒè¯•ç»“æœ...")
        debug_output = {
            "api_info": {
                "title": api_data["api_spec"].title,
                "version": api_data["api_spec"].version,
                "endpoints_count": len(api_data["api_spec"].endpoints)
            },
            "generation_summary": {
                "test_cases_count": len(generation_result["test_collection"].test_cases),
                "token_usage": generation_result["token_usage"].dict() if generation_result["token_usage"] else None
            },
            "sample_test_case": generation_result["test_collection"].test_cases[0].dict() if generation_result["test_collection"].test_cases else None
        }
        
        # ä¿å­˜è°ƒè¯•ç»“æœ
        output_file = "debug_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(debug_output, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è°ƒè¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"âœ… å®Œæ•´æµç¨‹è°ƒè¯•æˆåŠŸï¼")
        
        # å…³é—­HTTPå®¢æˆ·ç«¯
        await llm_client.client.aclose()
        
    except Exception as e:
        debug.handle_exception("debug_full_generation", e)


async def debug_specific_endpoint(debug: DebugHelper, endpoint_path: str = "/api/v1/auth/register") -> None:
    """è°ƒè¯•ç‰¹å®šçš„ç«¯ç‚¹"""
    debug.print_separator(f"è°ƒè¯•ç‰¹å®šç«¯ç‚¹: {endpoint_path}")
    
    try:
        # åŠ è½½é…ç½®å’ŒAPI
        config = await test_config_loading(debug)
        api_data = await test_api_parsing(debug)
        
        if not config or not api_data:
            print("âŒ å‰ç½®æ¡ä»¶å¤±è´¥")
            return
        
        # æŸ¥æ‰¾ç‰¹å®šç«¯ç‚¹
        target_endpoint = None
        for endpoint in api_data["api_spec"].endpoints:
            if endpoint.path == endpoint_path:
                target_endpoint = endpoint
                break
        
        if not target_endpoint:
            print(f"âŒ æœªæ‰¾åˆ°ç«¯ç‚¹: {endpoint_path}")
            available_paths = [ep.path for ep in api_data["api_spec"].endpoints]
            print(f"å¯ç”¨ç«¯ç‚¹: {available_paths[:10]}")
            return
        
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡ç«¯ç‚¹: {target_endpoint.method} {target_endpoint.path}")
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯å’Œç”Ÿæˆå™¨
        llm_client = LLMClient(config.llm)
        generator = TestCaseGenerator(llm_client, api_version="1.0")
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        print(f"\nğŸ”„ ä¸ºç«¯ç‚¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        result = await generator.generate_test_cases(target_endpoint)
        
        print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œå…±{len(result.test_cases.test_cases)}ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        # è¯¦ç»†è¾“å‡ºæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹
        for i, test_case in enumerate(result.test_cases.test_cases):
            print(f"\n--- æµ‹è¯•ç”¨ä¾‹ {i+1} ---")
            print(f"åç§°: {test_case.name}")
            # å®‰å…¨è·å–test_typeå€¼
            test_type = test_case.test_type.value if hasattr(test_case.test_type, 'value') else str(test_case.test_type)
            print(f"ç±»å‹: {test_type}")
            print(f"çŠ¶æ€ç : {test_case.expected_status}")
            print(f"æè¿°: {test_case.description}")
            if test_case.body:
                print(f"è¯·æ±‚ä½“: {json.dumps(test_case.body, indent=2, ensure_ascii=False)}")
            if test_case.tags:
                print(f"æ ‡ç­¾: {', '.join(test_case.tags)}")
        
        await llm_client.client.aclose()
        
    except Exception as e:
        debug.handle_exception("debug_specific_endpoint", e)


def main():
    """ä¸»å‡½æ•° - åœ¨è¿™é‡Œé€‰æ‹©è¦è¿è¡Œçš„è°ƒè¯•åŠŸèƒ½"""
    debug = DebugHelper()
    
    print("ğŸš€ CaseCraft è°ƒè¯•å·¥å…·å¯åŠ¨")
    print("=" * 60)
    
    # åœ¨è¿™é‡Œé€‰æ‹©è¦è¿è¡Œçš„è°ƒè¯•åŠŸèƒ½
    # å–æ¶ˆæ³¨é‡Šç›¸åº”çš„å‡½æ•°è°ƒç”¨å³å¯
    
    try:
        # é€‰æ‹©ä»¥ä¸‹ä»»æ„ä¸€ä¸ªæˆ–å¤šä¸ªå‡½æ•°è¿›è¡Œè°ƒè¯•:
        
        # 1. æµ‹è¯•å•ä¸ªç»„ä»¶
        # asyncio.run(test_config_loading(debug))
        # asyncio.run(test_api_parsing(debug))
        # config = asyncio.run(test_config_loading(debug))
        # if config:
        #     asyncio.run(test_llm_client(debug, config))
        
        # 2. ç«¯åˆ°ç«¯å®Œæ•´æµç¨‹æµ‹è¯• (æ¨è)
        # asyncio.run(debug_full_generation(debug))
        
        # 3. è°ƒè¯•ç‰¹å®šç«¯ç‚¹
        asyncio.run(debug_specific_endpoint(debug, "/api/v1/auth/register"))
        # asyncio.run(debug_specific_endpoint(debug, "/api/v1/products/"))
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åº")
    except Exception as e:
        debug.handle_exception("main", e)
    
    print("\nğŸ¯ è°ƒè¯•å®Œæˆ!")


if __name__ == "__main__":
    main()